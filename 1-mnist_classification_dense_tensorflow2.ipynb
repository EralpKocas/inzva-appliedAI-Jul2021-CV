{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both keras and tf datasets can be used. TFDS will be used to show the list of datasets.\n",
    "# TFDS is a high-level wrapper around tf.data.\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'blimp',\n",
       " 'bool_q',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'downsampled_imagenet',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gpt3',\n",
       " 'groove',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'i_naturalist2017',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mctaco',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quickdraw_bitmap',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'resisc45',\n",
       " 'robonet',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vctk',\n",
       " 'vgg_face2',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_questions',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_bio',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries for data exploration and further data operations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfds api to get mnist dataset\n",
    "# split to train and test\n",
    "# batch size -1, thus, no batch but could be done here.\n",
    "mnist_training, mnist_test = tfds.load('mnist', split=['train', 'test'], batch_size=-1, as_supervised=True)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(60000, 28, 28, 1), dtype=uint8, numpy=\n",
      "array([[[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]]], dtype=uint8)>, <tf.Tensor: shape=(60000,), dtype=int64, numpy=array([4, 1, 0, ..., 6, 1, 5])>)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(10000, 28, 28, 1), dtype=uint8, numpy=\n",
      "array([[[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]],\n",
      "\n",
      "\n",
      "       [[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]]], dtype=uint8)>, <tf.Tensor: shape=(10000,), dtype=int64, numpy=array([2, 0, 4, ..., 8, 0, 5])>)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_training_images, mnist_training_labels = mnist_training[0], mnist_training[1]\n",
    "mnist_test_images, mnist_test_labels = mnist_test[0], mnist_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_training_images.shape)\n",
    "print(mnist_training_labels.shape)\n",
    "\n",
    "print(mnist_test_images.shape)\n",
    "print(mnist_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualize first training image\n",
    "plt.imshow(mnist_training_images[0] ,cmap = 'gray')\n",
    "print(mnist_training_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# also, let's visualize first test image\n",
    "plt.imshow(mnist_test_images[0] ,cmap = 'gray')\n",
    "print(mnist_test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "255 0\n",
      "255 0\n",
      "9 0\n",
      "9 0\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "# reshape into trainable vectors\n",
    "num_training_images = mnist_training_images.shape[0]\n",
    "num_test_images = mnist_test_images.shape[0]\n",
    "\n",
    "img_width, img_height = mnist_training_images.shape[1], mnist_training_images.shape[2]\n",
    "\n",
    "# since dense layer, we have to flatten 28x28 to 784x1.\n",
    "mnist_training_images = tf.reshape(mnist_training_images, shape=(num_training_images, img_width * img_height))\n",
    "mnist_test_images = tf.reshape(mnist_test_images, shape=(num_test_images, img_width * img_height))\n",
    "\n",
    "# check the changes\n",
    "print(mnist_training_images.shape)\n",
    "print(mnist_test_images.shape)\n",
    "\n",
    "# another preprocessing step is to normalize data\n",
    "print(np.amax(mnist_training_images[0]),np.amin(mnist_training_images[0]))\n",
    "\n",
    "print(np.amax(mnist_test_images[0]),np.amin(mnist_test_images[0]))\n",
    "\n",
    "print(np.amax(mnist_training_labels),np.amin(mnist_training_labels))\n",
    "\n",
    "print(np.amax(mnist_test_labels),np.amin(mnist_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of data type and normalization of training data\n",
    "# main idea of normalization/standardization -> variables that are at different scale contribute different.\n",
    "# we want to reduce the \"bias\" as much as possible by these methods.\n",
    "# min-max is highly influenced by outliers! min and max values affect a lot!\n",
    "def preprocess(x, y):\n",
    "  x = tf.cast(x, tf.float32) / 255.0\n",
    "  y = tf.cast(y, tf.int64)\n",
    "\n",
    "  return x, y\n",
    "\n",
    "# one-hot labels and create dataloader with given batch size.\n",
    "def create_dataset(xs, ys, n_classes=10):\n",
    "  ys = tf.one_hot(ys, depth=n_classes)\n",
    "  return tf.data.Dataset.from_tensor_slices((xs, ys)) \\\n",
    "    .map(preprocess) \\\n",
    "    .shuffle(len(ys)) \\\n",
    "    .batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(mnist_training_images, mnist_training_labels)\n",
    "test_dataset = create_dataset(mnist_test_images, mnist_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.int64)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 10), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "train_dataset.element_spec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n",
      "(128, 10)\n",
      "tf.Tensor(\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.37254903\n",
      " 1.         0.24313726 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01176471 0.49019608 0.59607846 0.59607846 0.59607846 0.19215687\n",
      " 0.         0.         0.19215687 0.8392157  0.99607843 0.40392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18431373 0.8039216  0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.9019608  0.19215687 0.07450981\n",
      " 0.5686275  0.99607843 0.8117647  0.0627451  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.16862746 0.8901961  0.92941177 0.3882353  0.15686275 0.23529412\n",
      " 0.7137255  0.99607843 0.6313726  0.5803922  0.99607843 0.95686275\n",
      " 0.2509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.8392157  0.9882353\n",
      " 0.30980393 0.         0.         0.         0.03921569 0.85882354\n",
      " 0.99607843 0.99607843 0.99607843 0.7019608  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8392157  0.90588236 0.         0.\n",
      " 0.         0.43137255 0.73333335 0.9490196  0.99607843 0.99607843\n",
      " 0.87058824 0.11372549 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8392157  0.96862745 0.42745098 0.33333334 0.33333334 0.8392157\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.6784314  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23529412 0.9372549\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.84705883 0.29411766\n",
      " 0.8352941  0.9882353  0.24313726 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.08627451 0.41960785 0.41960785\n",
      " 0.29411766 0.09019608 0.03529412 0.20392157 0.99607843 0.6509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.53333336 0.99607843 0.5647059  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.12941177 0.90588236\n",
      " 0.91764706 0.14901961 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.5254902  0.99607843 0.54901963 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.654902   0.99215686 0.22352941 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.26666668 0.95686275 0.63529414\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.67058825 0.9490196  0.2627451  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23529412 0.9647059\n",
      " 0.61960787 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.6862745  0.9019608  0.14901961 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.9882353  0.41960785 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00392157 0.69803923 0.98039216 0.27450982\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01176471 0.7764706  0.7137255  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ], shape=(784,), dtype=float32)\n",
      "tf.Tensor([0 0 0 0 0 0 0 0 0 1], shape=(10,), dtype=int64)\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# check the dataloader\n",
    "batch_images, batch_labels = next(iter(train_dataset))\n",
    "print(batch_images.shape)\n",
    "print(batch_labels.shape)\n",
    "print(batch_images[0])\n",
    "print(batch_labels[0])\n",
    "print(np.amax(batch_images[0]),np.amin(batch_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe040d4b1c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize first batch training image to show it is corresponds to same class with printed label.\n",
    "plt.imshow(tf.reshape(batch_images[0], shape=(img_width, img_height, 1)) ,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "input_shape = 784\n",
    "label_shape = 10\n",
    "\n",
    "lr = 0.003\n",
    "\n",
    "layer_neurons = [\n",
    "    [input_shape, 200],\n",
    "    [200, 80],\n",
    "    [80, label_shape],\n",
    "]\n",
    "\n",
    "bias_shapes = [200, 80, label_shape]\n",
    "# xaiver uniform initializer\n",
    "initializer = tf.initializers.glorot_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dense layer, also, you can use TF2 API or Keras!\n",
    "def dense_layer(inputs, weights, bias):\n",
    "    return tf.nn.sigmoid(tf.matmul(inputs, weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for initialization of weights and biases\n",
    "def get_weight(shape, name):\n",
    "    return tf.Variable(initializer(shape), name=name, trainable=True, dtype=tf.float32)\n",
    "\n",
    "def get_bias(shape, name):\n",
    "    return tf.Variable(initializer([shape]), name=name, trainable=True, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define weights and bias lists to use in model\n",
    "weights = []\n",
    "bias = []\n",
    "i = 0\n",
    "for layer in layer_neurons:\n",
    "    weights.append(get_weight(layer, 'weight{}'.format(i)))\n",
    "    i+=1\n",
    "\n",
    "i = 0\n",
    "for layer in bias_shapes:\n",
    "    bias.append(get_bias(layer, 'bias{}'.format(i)))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model with initialized weights and biases\n",
    "def model(input):\n",
    "    l1 = dense_layer(input, weights[0], bias[0])\n",
    "    l2 = dense_layer(l1, weights[1], bias[1])\n",
    "    l3 = dense_layer(l2, weights[2], bias[2])\n",
    "    #return tf.nn.softmax(l3)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "optimizer = tf.optimizers.Adam(lr)\n",
    "\n",
    "# it is with logits because we return the predictions without applying softmax!\n",
    "# applied directly to prediction probabilities.\n",
    "def loss(pred, target):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define our train_step here\n",
    "# tf.GradientTape is used for recording operations for automatic differentiation. backward pass!\n",
    "def train_step(model, inputs, outputs, epoch):\n",
    "    epoch_loss_avg = None\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(model(inputs), outputs)\n",
    "        grads = tape.gradient(current_loss, weights)\n",
    "        optimizer.apply_gradients(zip(grads, weights))\n",
    "    \n",
    "    epoch_loss_avg = tf.reduce_mean(current_loss)\n",
    "    \n",
    "    return epoch_loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- On epoch 0 ---\n",
      "| Loss:  1.63039112\n",
      "--- On epoch 1 ---\n",
      "| Loss:  1.51271236\n",
      "--- On epoch 2 ---\n",
      "| Loss:  1.49572599\n",
      "--- On epoch 3 ---\n",
      "| Loss:  1.48671043\n",
      "--- On epoch 4 ---\n",
      "| Loss:  1.48095512\n",
      "--- On epoch 5 ---\n",
      "| Loss:  1.47677255\n",
      "--- On epoch 6 ---\n",
      "| Loss:  1.47435224\n",
      "--- On epoch 7 ---\n",
      "| Loss:  1.47188127\n",
      "--- On epoch 8 ---\n",
      "| Loss:  1.47050095\n",
      "--- On epoch 9 ---\n",
      "| Loss:  1.46922874\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "# batch by batch for each epoch -> traverse over all training dataset.\n",
    "# total loss is divided by number of iterations to get average loss for each batch.\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    for train_data in train_dataset:\n",
    "        batch_images, batch_labels = train_data\n",
    "        iter_loss = train_step(model, batch_images, batch_labels, epoch)\n",
    "        epoch_loss += iter_loss\n",
    "        i+=1\n",
    "    print(\"--- On epoch {} ---\".format(epoch))\n",
    "    tf.print(\"| Loss: \", epoch_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778\n"
     ]
    }
   ],
   "source": [
    "acc = 0 \n",
    "# use trained model over test dataset and normalize with number of test samples\n",
    "# obtain accuracy!\n",
    "for test_data in test_dataset:\n",
    "    batch_images, batch_labels = test_data\n",
    "    predictions = model(batch_images)\n",
    "    predictions = tf.nn.softmax(predictions)\n",
    "    equality = tf.math.equal(np.argmax(predictions, axis=1), np.argmax(batch_labels, axis=1))\n",
    "    acc += np.sum(equality)\n",
    "acc /= 10000\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
